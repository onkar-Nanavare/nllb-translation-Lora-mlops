name: LoRA Training Workflow

on:
  push:
    branches:
      - main
    paths:
      - 'nllb-translation-service/data/**'
      - 'training/train_lora.py'
      - 'nllb-translation-service/config/**'
  workflow_dispatch:

jobs:
  lora_training:
    runs-on: [self-hosted, Windows, X64, gpu, ml]
    timeout-minutes: 360  # up to 6 hours

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Verify Python
        run: |
          python --version
          pip --version

      - name: Create venv (optional but clean)
        run: |
          python -m venv venv
          venv\Scripts\activate
          python -m pip install --upgrade pip

      - name: Install dependencies
        run: |
          venv\Scripts\activate
          pip install -r requirements.txt
          pip install -r requirements-training.txt
          pip install accelerate datasets transformers peft bitsandbytes

      - name: Debug paths
        run: |
          dir
          dir nllb-translation-service\data
          dir nllb-translation-service\config

      - name: Run LoRA Training (GPU)
        run: |
          venv\Scripts\activate
          python training/train_lora.py ^
            --data-file nllb-translation-service/data/new_data.tsv ^
            --glossary-file nllb-translation-service/data/glossary.json ^
            --output-dir ./models/custom-nllb-fast ^
            --model-name facebook/nllb-200-distilled-600M ^
            --source-lang eng_Latn ^
            --target-lang hin_Deva ^
            --config nllb-translation-service/config/training_config.yaml

      - name: Upload Trained Model
        uses: actions/upload-artifact@v4
        with:
          name: trained-model-lora
          path: ./models/custom-nllb-fast
