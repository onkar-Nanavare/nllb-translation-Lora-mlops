name: LoRA Auto Training (Self-Hosted GPU)

on:
  push:
    branches:
      - main
    paths:
      - "nllb-translation-service/data/**"
      - "training/**"
      - ".github/workflows/lora-train.yml"
  workflow_dispatch:

jobs:
  lora_training:
    runs-on: [self-hosted, Windows, X64, gpu, ml]
    timeout-minutes: 720

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Use system Python (no setup-python)
        run: |
          python --version
          pip --version

      - name: Create venv & install deps
        run: |
          python -m venv venv
          .\venv\Scripts\activate
          pip install --upgrade pip
          pip install -r requirements.txt
          pip install -r requirements-training.txt
          pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121
          pip install transformers peft accelerate datasets bitsandbytes

      - name: Run LoRA Training
        run: |
          .\venv\Scripts\activate
          python training/train_lora.py ^
            --data-file nllb-translation-service/data/new_data.tsv ^
            --glossary-file nllb-translation-service/data/glossary.json ^
            --output-dir models/custom-nllb-fast ^
            --model-name facebook/nllb-200-distilled-600M ^
            --source-lang eng_Latn ^
            --target-lang hin_Deva ^
            --config nllb-translation-service/config/training_config.yaml

      - name: Upload trained model
        uses: actions/upload-artifact@v4
        with:
          name: custom-nllb-lora
          path: models/custom-nllb-fast
