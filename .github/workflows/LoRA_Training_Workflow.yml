name: LoRA_Training_Workflow

on:
  push:
    branches:
      - main
    paths:
      - 'nllb-translation-service/data/**'         
      - 'nllb-translation-service/training/**'
      - 'nllb-translation-service/config/**'
  workflow_dispatch:

jobs:
  lora_training:
    runs-on: [self-hosted, Windows, X64, gpu, ml]
    timeout-minutes: 720  # 12 hours (your PC, not GitHub)

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.10"

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          pip install -r requirements-training.txt
          pip install accelerate datasets transformers peft
          pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121

      - name: Run LoRA Training (GPU safe config)
        env:
          CUDA_VISIBLE_DEVICES: "0"
        run: |
          python training/train_lora.py ^
            --data-file nllb-translation-service/data/new_data.tsv ^
            --glossary-file nllb-translation-service/data/glossary.json ^
            --output-dir ./models/custom-nllb-fast ^
            --model-name facebook/nllb-200-distilled-600M ^
            --source-lang eng_Latn ^
            --target-lang hin_Deva ^
            --config nllb-translation-service/config/training_config.yaml

      - name: Upload Trained LoRA Adapter
        uses: actions/upload-artifact@v4
        with:
          name: trained-model-lora
          path: ./models/custom-nllb-fast
